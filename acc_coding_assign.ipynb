{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impossible-pricing",
   "metadata": {},
   "source": [
    "**load in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passing-soccer",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Acc_challenge/Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os \n",
    "import pandas as pd\n",
    "path = os.path.abspath(\"Untitled.ipynb\")\n",
    "print(path)\n",
    "# need to add a function to grab the path more nicely \n",
    "\n",
    "f = open(\"/Users/mac/Desktop/Acc_challenge/venv/MultiWOZ2_3/data.json\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-birmingham",
   "metadata": {},
   "source": [
    "**loop over the data and record an instance for everything** \n",
    "Each text instance % 0 == request, % 1 == response. - record instances \n",
    "\n",
    "*dialog_act*:\n",
    "\n",
    "Each action is further broken into a smaller subset of one or more intents. \n",
    "Record in dialog_act \n",
    "\n",
    "**further** \n",
    "identify overall intent of conversation per unique convo_id \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dedicated-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 4)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "identifies the json documents where only train occurs \n",
    "'''\n",
    "\n",
    "# each key refers to a conversation of X exchanges \n",
    "# extract the conversation goals \n",
    "conversation_list=[]\n",
    "for key in data.keys(): # each conversation  \n",
    "    conversation_goals_list=[]\n",
    "    for item in data[key][\"goal\"]: \n",
    "        #if isinstance(data[key][\"goal\"][item], dict): # ignore list instance\n",
    "           if item != \"message\" and item != \"topic\": # ignore topic and message\n",
    "                if len(data[key][\"goal\"][item].keys()) > 0:\n",
    "                    conversation_goals_list.append(item)\n",
    "    conversation_list.append(conversation_goals_list)\n",
    "\n",
    "df_convos = pd.DataFrame({\"convo_id\": list(data.keys()), \"convo_goals\": conversation_list})\n",
    "# print(df_convos.head())\n",
    "# print(df_convos.shape)\n",
    "\n",
    "# returns an integer assertion if value present\n",
    "def detect_target_value(row):\n",
    "    if \"train\" in row:\n",
    "        return 1 \n",
    "    return 0 \n",
    "\n",
    "# count the number of conversations \n",
    "def count_topics(row):\n",
    "    return len(row)\n",
    "    \n",
    "df_convos[\"train\"] = df_convos['convo_goals'].apply(detect_target_value) # looks for instance of 'train'\n",
    "df_convos[\"num_topics\"] = df_convos[\"convo_goals\"].apply(count_topics) # looks for single instances \n",
    "df_train = df_convos.query('train == 1 & num_topics == 1') # creates a new dataframe contraining ids of only train and train only discussions \n",
    "\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-house",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "framed-adjustment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3542, 4)\n",
      "(1771, 4)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Having identified where only train occurs, this cell extracts agent only utterance.\n",
    "The corpus is constructed on a turn basedd appraoch and included is a turn indicator ( turn_id). \n",
    "Applying a modulous of 2, we separate out customer and agent text. \n",
    "'''\n",
    "#print(data.keys())\n",
    "# extract the train dictionary \n",
    "train_dict = {key: value for key, value in data.items() if key in list(df_train.convo_id)}\n",
    "\n",
    "# drill into the log and extract the text || dialog_act || turn_id\n",
    "text_list = []\n",
    "dialog_list = [] \n",
    "turn_id_list = [] \n",
    "id_list = [] \n",
    "for k, v in train_dict.items():     \n",
    "    for  value in v['log']:\n",
    "        text_list.append(value[\"text\"])\n",
    "        dialog_list.append(value[\"dialog_act\"].keys())\n",
    "        turn_id_list.append(value[\"turn_id\"])\n",
    "        id_list.append(k)\n",
    "\n",
    "\n",
    "df_utterances = pd.DataFrame({\"ids\": id_list, \"turns\": turn_id_list, \"dialog_intent\" : dialog_list, \"text\": text_list})\n",
    "print(df_utterances.shape)\n",
    "\n",
    "\n",
    "# def distinguishAgentCustomer(row):\n",
    "#     value = row % 2\n",
    "#     return value \n",
    "\n",
    "#df_utterances[\"speaker\"] = df_utterances.turns.apply(distinguishAgentCustomer)\n",
    "#print(df_utterances.speaker.sum())\n",
    "df_agent_utterances = df_utterances[df_utterances.turns % 2 == 1]\n",
    "print(df_agent_utterances.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-camping",
   "metadata": {},
   "source": [
    "**intent discovery**:\n",
    "\n",
    "Having separated out agent utterances, lets further drill into them and see if we can identify some pattern found there that can be useful in a down-the-line task. In what follows we will apply LDA to the text and see if there exists some pattern we like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-merchant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
