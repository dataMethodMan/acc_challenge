{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6fd9b4",
   "metadata": {},
   "source": [
    "\n",
    "1.  Data importation: extract all agent utterances of conversations that have “taxi” as only goal (taxi booking service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a02736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "import pandas as pd \n",
    "# obtain path to the script \n",
    "dir_path = os.path.dirname(\"__file__\")\n",
    "\n",
    "data_path=os.path.join(dir_path, \"data.json\") # expects that the data file is stored in the current directory\n",
    "f=open(data_path)\n",
    "data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16754cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 345 conversations that feature 'train' only\n",
      "(3542, 4)\n",
      "(1771, 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "identifies instances in json documents where only 'train' occurs\n",
    "\"\"\"\n",
    "\n",
    "# each key refers to conversation of X exchanges\n",
    "# extract the conversation goals \n",
    "conversation_list=[] # a list to hold the list of all exchanges per conversation \n",
    "for key in data.keys(): # for each conversation \n",
    "    conversation_goals_list=[] # for each conversation keep all exchanges \n",
    "    for item in data[key][\"goal\"]:\n",
    "        if item != \"message\" and item != \"topic\": # ignore topic and message \n",
    "            # loop through and grab all populated conversation goals \n",
    "            if len(data[key][\"goal\"][item].keys()) > 0: # skip empty goals \n",
    "                conversation_goals_list.append(item)\n",
    "    conversation_list.append(conversation_goals_list) # list of convo_goals per conversation \n",
    "        \n",
    "        \n",
    "# populate a df with unique conversation id, and a list of respective goals \n",
    "df_convo=pd.DataFrame({\"convo_id\" : list(data.keys()), \"convo_goals\": conversation_list})\n",
    "#print(df_convo.shape)\n",
    "\n",
    "# method to determine if taxi features as a goal \n",
    "def detect_target_values(row):\n",
    "    # first see if train is present \n",
    "    if \"train\" in row:\n",
    "        # excluding all multiple-topic conversations \n",
    "        if len(row) == 1:\n",
    "            return 1\n",
    "    return 0\n",
    "# identifies all instances of train and further filters all non singleton instances of 'train' conversations\n",
    "df_convo[\"train\"] = df_convo[\"convo_goals\"].apply(detect_target_values) \n",
    "# create a sub df with only train based topics. \n",
    "df_train=df_convo[df_convo.train == 1]\n",
    "print(\"There are {} conversations that feature 'train' only\".format(df_train.shape[0]))\n",
    "\n",
    "# having identified are target conversations, we iterate through the data and pull out the info related to our keys\n",
    "train_dict = {key: value for key, value in data.items() if key in list(df_train.convo_id)}\n",
    "\n",
    "# drill into the 'logs' and extract : text || dialog_act || turn_id\n",
    "text_list=[]\n",
    "dialog_list=[] \n",
    "turn_id_list=[]\n",
    "id_list=[]\n",
    "for k,v in train_dict.items():\n",
    "    for value in v['log']:\n",
    "        text_list.append(value['text'])\n",
    "        dialog_list.append(value['dialog_act'].keys())\n",
    "        turn_id_list.append(value['turn_id'])\n",
    "        id_list.append(k) # retain conversation reference \n",
    "        \n",
    "# populate a dataframe with our targeted data \n",
    "df_utterances=pd.DataFrame({\"ids\": id_list, \"turns\":turn_id_list, \"dialog_intent\": dialog_list, \"text\": text_list })\n",
    "print(df_utterances.shape)\n",
    "\n",
    "# only retain conversations related to the agent, i.e modulus 2\n",
    "df_agent_utterances=df_utterances[df_utterances.turns % 2==1]\n",
    "print(df_agent_utterances.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_utterances.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e1bd6",
   "metadata": {},
   "source": [
    "2. Preprocessing: perform any preprocessing/utterance encoding you may deem necessary for the tasks below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08b45121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string \n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "# run below if having trouble with accessing stopwords\n",
    "# need only be run once. \n",
    "#nltk.download('stopwords')\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "class PreProcessText:\n",
    "    \"\"\" class that performs tfidf on text\"\"\"\n",
    "    def __init__(self, df):\n",
    "        \"\"\" init accepts the dataframe, adds the text col and processes the tfidf\"\"\"\n",
    "        self.all_rows=[]\n",
    "        self.df = df\n",
    "        # initialise vectoriser, limit terms to ones that have a % frequency  x > 1 and x < 90\n",
    "        self.vectoriser=TfidfVectorizer(min_df=0.01, max_df=0.90)\n",
    "        # vectorise the text \n",
    "        self.df['body_text'] = self.df.text.apply(self.create_vsm)\n",
    "        \n",
    "        \n",
    "    def create_vsm(self, convo):\n",
    "        # mask some generic symbols \n",
    "        convo=re.sub(\"\\d+:\\d+\", \"time_stamp\", convo) # substitute time ref for a generic stamp: 10:10 -> time_Stamp\n",
    "        convo= re.sub(\"\\d+\\.\\d+\", \"money_ref\", convo) # sub money ref for generic stamp: 12.50 -> money_ref\n",
    "        convo=re.sub(\"[A-Z]{1,}\\d+\", \"ref_num\", convo)# sub train ref for generic stamp: TR900 -> ref_num\n",
    "        \n",
    "        # remove punctuation \n",
    "        removeSyms = string.punctuation \n",
    "        # include underscore for above masks \n",
    "        removeSyms = removeSyms.replace(\"_\", \"\")\n",
    "        pattern=r\"[{}]\".format(removeSyms)\n",
    "        # apply the pattern to the string, remove space, lowercase \n",
    "        convo = re.sub(pattern, \" \", convo.strip().lower())\n",
    "        \n",
    "        # finally, tokenize and exclude stopwords \n",
    "        sent=[word for word in convo.split() if word not in stop]\n",
    "        return \" \".join(sent) \n",
    "        \n",
    "    \n",
    "    def vectorise(self):\n",
    "        \"\"\"method runs tfidf vectoriser\"\"\"\n",
    "        text = self.df.body_text.values\n",
    "        X = self.vectoriser.fit_transform(text)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ac099",
   "metadata": {},
   "source": [
    "4. Utterance classification: train and evaluate a supervised utterance classifier that recognizes utterances of these 5 most common utterance types. How well is the classifier working on unseen utterances of known types? Could you use this classifier to realize a utterance does not belong to any known type, yet properly classify utterances of known types? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd786c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_12478/4059216449.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df['body_text'] = self.df.text.apply(self.create_vsm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fit 2 clusters\n",
      " Fit 3 clusters\n",
      " Fit 4 clusters\n",
      " Fit 5 clusters\n",
      " Fit 6 clusters\n",
      " Fit 7 clusters\n",
      " Fit 8 clusters\n",
      " Fit 9 clusters\n",
      " Fit 10 clusters\n",
      " Fit 11 clusters\n",
      " Fit 12 clusters\n",
      " Fit 13 clusters\n",
      " Fit 14 clusters\n",
      " Fit 15 clusters\n",
      " Fit 16 clusters\n",
      " Fit 17 clusters\n",
      " Fit 18 clusters\n",
      " Fit 19 clusters\n",
      " Fit 20 clusters\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_processor=PreProcessText(df_agent_utterances)\n",
    "\n",
    "def find_optimal_num_clusters(data, max_k):\n",
    "    \"\"\" method takes data and target num_clusters and determines optimal number of clusters\"\"\"\n",
    "    iters=range(2,max_k + 1, 1) # set iteration number \n",
    "    inertia_values=[]\n",
    "    \n",
    "    for k in iters:\n",
    "        inertia_values.append(KMeans(n_clusters=k, init='k-means++', \n",
    "                                random_state=10).fit(data).inertia_)\n",
    "        print(' Fit {} clusters'.format(k))\n",
    "        \n",
    "    (f, ax) = plt.subplots(1,1)\n",
    "    ax.plot(iters, inertia_values, marker=\"o\")\n",
    "    ax.set_xlabel(\"cluster nums\")\n",
    "    ax.set_xticks(iters)\n",
    "    ax.set_xticklabels(iters)\n",
    "    ax.set_ylabel(\"inertia\")\n",
    "    ax.set_title(\"inertia per cluster\")\n",
    "    plt.show()\n",
    "\n",
    "X=text_processor.vectorise()\n",
    "find_optimal_num_clusters(X, 20)\n",
    "# optimal number of clusters == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758a405",
   "metadata": {},
   "source": [
    "running the above cell would suggest that the ideal number of clusters would be 10 \n",
    "Further work could focus on drilling into the differences of the clusters, though the suspicion is that there is not enough input data to generate distinct rich clusters. I.E much of the input text is very similar. \n",
    "Proceeding with the assignment brief it was elected to only focus on 5 sub topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a0063de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'else , trip , anything , need , departing , goodbye , help , thank , '\n",
      "    'destination , welcome',\n",
      " 1: 'depart , minutes , day , arrive , trains , travel , leave , would , like '\n",
      "    ', time',\n",
      " 2: 'fee , anything , payable , money_ref , else , booked , station , gbp , '\n",
      "    'number , reference',\n",
      " 3: 'towninfo , centre , wonderful , traveling , good , thank , nice , welcome '\n",
      "    ', great , day',\n",
      " 4: 'work , like , cambridge , book , would , arrives , leaves , train , '\n",
      "    'ref_num , time_stamp'}\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_12478/3754958004.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_processor.df['y'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "def get_cluster_themes(data,clusters,labels,n_terms):\n",
    "    \"\"\" method determines the theme of each cluster\"\"\"\n",
    "    themes_dict={}\n",
    "    df=pd.DataFrame(data.todense()).groupby(clusters).mean() # creates a row for each cluster and a column per term \n",
    "    for (i,r) in df.iterrows():\n",
    "        themes_dict[i] = \" , \".join(labels[t] for t in np.argsort(r)[-n_terms:]) # join the weights table that correspod to the top n terms in the cluser row \n",
    "    return themes_dict\n",
    "\n",
    "n5_clusters=KMeans(n_clusters=5, init=\"k-means++\", random_state=10)\n",
    "y_pred=n11_clusters.fit_predict(X.toarray())\n",
    "text_processor.df['y'] = y_pred\n",
    "themes_dict=get_cluster_themes(X, y_pred, text_processor.vectoriser.get_feature_names(), 10)\n",
    "print(pp.pprint(themes_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf50fc6",
   "metadata": {},
   "source": [
    "Having run the above cell one could select 5 labels for the documents as follows:\n",
    "1. saluations-leaving\n",
    "2. train-departure_needs-request\n",
    "3. money-request\n",
    "4. arrival-instructions\n",
    "5. booking-depart-instructions\n",
    "\n",
    "Alternatively one could apply LDA to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0fd2c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim import corpora\n",
    "from gensim import models \n",
    "import numpy as np\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "\n",
    "# take the processed doc and return to vector to suit gensim input type\n",
    "tokenised_text = [doc.split() for doc in text_processor.df.body_text.values]\n",
    "\n",
    "# cast to a dictionary \n",
    "dictionary=Dictionary(tokenised_text)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenised_text]\n",
    "#print(len(corpus))\n",
    "\n",
    "# to load the dictionary \n",
    "temp=dictionary[0]\n",
    "\n",
    "id2word=dictionary.id2token\n",
    "model=LdaModel(corpus=corpus,\n",
    "                id2word=id2word,\n",
    "                  alpha=\"auto\",\n",
    "                  eta=\"auto\",\n",
    "              iterations=400, \n",
    "              num_topics=5,\n",
    "              passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "98e02aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp  refnum  would  train  like  cambridge  book  leaves  arrives  leaving\n",
      "\n",
      "time  trains  day  like  leave  would  arrive  travel  need  available\n",
      "\n",
      "pounds  moneyref  help  destination  could  departing  minutes  glad  price  departure\n",
      "\n",
      "number  reference  else  anything  moneyref  gbp  station  help  booked  payable\n",
      "\n",
      "day  welcome  thank  great  trip  goodbye  using  cambridge  centre  nice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(model.show_topics())\n",
    "for i, r in iter(model.show_topics()):\n",
    "    print(re.sub(r'[^a-z ]+', '', r))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b55e4c4",
   "metadata": {},
   "source": [
    "LDA topics seem to produce less cohesive topic types, loosely speaking one could argue that themes are \n",
    "1. specific-train-time-request\n",
    "2. general-train-time-request\n",
    "3. payment-request\n",
    "4. end-of-transaction\n",
    "5. saluations-bye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767bdd5d",
   "metadata": {},
   "source": [
    "5. Utterance classification: train and evaluate a supervised utterance classifier that recognizes utterances of these 5 most common utterance types. How well is the classifier working on unseen utterances of known types? Could you use this classifier to realize a utterance does not belong to any known type, yet properly classify utterances of known types? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7101c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ids  turns                  dialog_intent  \\\n",
      "1   SNG0297.json      1                (Train-Request)   \n",
      "3   SNG0297.json      3  (Train-Inform, Train-Request)   \n",
      "5   SNG0297.json      5                 (Train-Inform)   \n",
      "7   SNG0297.json      7                  (general-bye)   \n",
      "9  SNG01450.json      1                (Train-Request)   \n",
      "\n",
      "                                                text  \\\n",
      "1  I 'll be glad to help . You would like to from...   \n",
      "3  I have seven trains , could you tell me when y...   \n",
      "5                             TR7943 leaves at 11:39   \n",
      "7                                 Have a great day !   \n",
      "9      What time and day are you looking to travel ?   \n",
      "\n",
      "                                           body_text  y  \n",
      "1  glad help would like london liverpool street d...  0  \n",
      "3          seven trains could tell would like arrive  1  \n",
      "5                          ref_num leaves time_stamp  4  \n",
      "7                                          great day  3  \n",
      "9                            time day looking travel  1  \n"
     ]
    }
   ],
   "source": [
    "print(text_processor.df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0ba9b204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saluations-leaving               577\n",
      "booking-depart-instructions      427\n",
      "train-departure_needs-request    325\n",
      "arrival-instructions             228\n",
      "money-request                    214\n",
      "Name: term_intent, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_12478/150045704.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_processor.df['term_intent'] = text_processor.df.y.apply(cluster_convert)\n"
     ]
    }
   ],
   "source": [
    "def cluster_convert(row):\n",
    "    ''' method iterates over y (the cluster value assigned the doc) \n",
    "    and converts it to a text label which we manually determined'''\n",
    "    \n",
    "    intents = [\"saluations-leaving\",\"train-departure_needs-request\", \"money-request\", \n",
    "                               \"arrival-instructions\", \"booking-depart-instructions\"]\n",
    "    return intents[row]\n",
    "\n",
    "\n",
    "text_processor.df['term_intent'] = text_processor.df.y.apply(cluster_convert)\n",
    "#print(text_processor.df.head())\n",
    "print(text_processor.df.term_intent.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "84c731c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ids', 'turns', 'dialog_intent', 'text', 'body_text', 'y',\n",
      "       'term_intent'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create a test/train split in our data\n",
    "print(text_processor.df.columns)\n",
    "from sklearn.model_selection import train_test_split \n",
    "train, test = train_test_split(text_processor.df, test_size=0.2)\n",
    "\n",
    "train_data=train.body_text\n",
    "train_labels=train.term_intent\n",
    "\n",
    "test_data=test.body_text\n",
    "test_labels=test.term_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "51abdc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use large pretrained sentence embeddings that include phrase usage\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder-large/5'\n",
    "embed = hub.KerasLayer(module_url, trainable=True, name='USE_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "74e6ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding \n",
    "y_train=pd.get_dummies(train_labels)\n",
    "y_test=pd.get_dummies(test_labels)\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model(embed):\n",
    "    model=Sequential([\n",
    "        Input(shape=[], dtype=tf.string), \n",
    "        embed,\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model \n",
    "model = build_model(embed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84874770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.3840 - accuracy: 0.7747INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3292s 91s/step - loss: 1.3840 - accuracy: 0.7747 - val_loss: 1.3309 - val_accuracy: 0.7711\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.2700 - accuracy: 0.8083 INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 5163s 143s/step - loss: 1.2700 - accuracy: 0.8083 - val_loss: 1.2143 - val_accuracy: 0.8275\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.1563 - accuracy: 0.8551WARNING:tensorflow:5 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1943a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x1943a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 7725s 215s/step - loss: 1.1563 - accuracy: 0.8551 - val_loss: 1.1052 - val_accuracy: 0.8768\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0534 - accuracy: 0.8728 WARNING:tensorflow:6 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x1943a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x1943a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 7902s 219s/step - loss: 1.0534 - accuracy: 0.8728 - val_loss: 1.0078 - val_accuracy: 0.9014\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9630 - accuracy: 0.8949 WARNING:tensorflow:7 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x1943a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x1943a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 12489s 347s/step - loss: 0.9630 - accuracy: 0.8949 - val_loss: 0.9233 - val_accuracy: 0.9261\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.8854 - accuracy: 0.9302 "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"tmp/checkpoint\", monitor=\"val_loss\", save_best_only=True)\n",
    "\n",
    "train_logs=model.fit(train_data, y_train, validation_split=0.20, \n",
    "                    epochs = 10, \n",
    "                    callbacks=[checkpoint], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preds=[]\n",
    "rawPreds = model.predict(test_data)\n",
    "for j in range(rawPreds.shape[0]):\n",
    "    pos=rawPreds[j].argmax()\n",
    "    Preds.append(y_test.columns[pos])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(Preds, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e234f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
