{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be0e76b",
   "metadata": {},
   "source": [
    "\n",
    "1.  Data importation: extract all agent utterances of conversations that have “taxi” as only goal (taxi booking service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e153ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "import pandas as pd \n",
    "# obtain path to the script \n",
    "dir_path = os.path.dirname(\"__file__\")\n",
    "\n",
    "data_path=os.path.join(dir_path, \"data.json\") # expects that the data file is stored in the current directory\n",
    "f=open(data_path)\n",
    "data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7099d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 345 conversations that feature 'train' only\n",
      "(3542, 4)\n",
      "(1771, 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "identifies instances in json documents where only 'train' occurs\n",
    "\"\"\"\n",
    "\n",
    "# each key refers to conversation of X exchanges\n",
    "# extract the conversation goals \n",
    "conversation_list=[] # a list to hold the list of all exchanges per conversation \n",
    "for key in data.keys(): # for each conversation \n",
    "    conversation_goals_list=[] # for each conversation keep all exchanges \n",
    "    for item in data[key][\"goal\"]:\n",
    "        if item != \"message\" and item != \"topic\": # ignore topic and message \n",
    "            # loop through and grab all populated conversation goals \n",
    "            if len(data[key][\"goal\"][item].keys()) > 0: # skip empty goals \n",
    "                conversation_goals_list.append(item)\n",
    "    conversation_list.append(conversation_goals_list) # list of convo_goals per conversation \n",
    "        \n",
    "        \n",
    "# populate a df with unique conversation id, and a list of respective goals \n",
    "df_convo=pd.DataFrame({\"convo_id\" : list(data.keys()), \"convo_goals\": conversation_list})\n",
    "#print(df_convo.shape)\n",
    "\n",
    "# method to determine if taxi features as a goal \n",
    "def detect_target_values(row):\n",
    "    # first see if train is present \n",
    "    if \"train\" in row:\n",
    "        # excluding all multiple-topic conversations \n",
    "        if len(row) == 1:\n",
    "            return 1\n",
    "    return 0\n",
    "# identifies all instances of train and further filters all non singleton instances of 'train' conversations\n",
    "df_convo[\"train\"] = df_convo[\"convo_goals\"].apply(detect_target_values) \n",
    "# create a sub df with only train based topics. \n",
    "df_train=df_convo[df_convo.train == 1]\n",
    "print(\"There are {} conversations that feature 'train' only\".format(df_train.shape[0]))\n",
    "\n",
    "# having identified are target conversations, we iterate through the data and pull out the info related to our keys\n",
    "train_dict = {key: value for key, value in data.items() if key in list(df_train.convo_id)}\n",
    "\n",
    "# drill into the 'logs' and extract : text || dialog_act || turn_id\n",
    "text_list=[]\n",
    "dialog_list=[] \n",
    "turn_id_list=[]\n",
    "id_list=[]\n",
    "for k,v in train_dict.items():\n",
    "    for value in v['log']:\n",
    "        text_list.append(value['text'])\n",
    "        dialog_list.append(value['dialog_act'].keys())\n",
    "        turn_id_list.append(value['turn_id'])\n",
    "        id_list.append(k) # retain conversation reference \n",
    "        \n",
    "# populate a dataframe with our targeted data \n",
    "df_utterances=pd.DataFrame({\"ids\": id_list, \"turns\":turn_id_list, \"dialog_intent\": dialog_list, \"text\": text_list })\n",
    "print(df_utterances.shape)\n",
    "\n",
    "# only retain conversations related to the agent, i.e modulus 2\n",
    "df_agent_utterances=df_utterances[df_utterances.turns % 2==1]\n",
    "print(df_agent_utterances.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7232a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ids  turns                  dialog_intent  \\\n",
      "0  SNG0297.json      0                 (Train-Inform)   \n",
      "1  SNG0297.json      1                (Train-Request)   \n",
      "2  SNG0297.json      2                 (Train-Inform)   \n",
      "3  SNG0297.json      3  (Train-Inform, Train-Request)   \n",
      "4  SNG0297.json      4  (Train-Inform, Train-Request)   \n",
      "\n",
      "                                                text  \n",
      "0  I am looking for a train departing from london...  \n",
      "1  I 'll be glad to help . You would like to from...  \n",
      "2  Cambridge . I 'd like to leave after 10:00 on ...  \n",
      "3  I have seven trains , could you tell me when y...  \n",
      "4  Just any time after 10:00 , can I get the trai...  \n"
     ]
    }
   ],
   "source": [
    "print(df_utterances.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5fe46",
   "metadata": {},
   "source": [
    "2. Preprocessing: perform any preprocessing/utterance encoding you may deem necessary for the tasks below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b82994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string \n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "# run below if having trouble with accessing stopwords\n",
    "# need only be run once. \n",
    "#nltk.download('stopwords')\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "class PreProcessText:\n",
    "    \"\"\" class that performs tfidf on text\"\"\"\n",
    "    def __init__(self, df):\n",
    "        \"\"\" init accepts the dataframe, adds the text col and processes the tfidf\"\"\"\n",
    "        self.all_rows=[]\n",
    "        self.df = df\n",
    "        # initialise vectoriser, limit terms to ones that have a % frequency  x > 1 and x < 90\n",
    "        self.vectoriser=TfidfVectorizer(min_df=0.01, max_df=0.90)\n",
    "        # vectorise the text \n",
    "        self.df['body_text'] = self.df.text.apply(self.create_vsm)\n",
    "        \n",
    "        \n",
    "    def create_vsm(self, convo):\n",
    "        # mask some generic symbols \n",
    "        convo=re.sub(\"\\d+:\\d+\", \"time_stamp\", convo) # substitute time ref for a generic stamp: 10:10 -> time_Stamp\n",
    "        convo= re.sub(\"\\d+\\.\\d+\", \"money_ref\", convo) # sub money ref for generic stamp: 12.50 -> money_ref\n",
    "        convo=re.sub(\"[A-Z]{1,}\\d+\", \"ref_num\", convo)# sub train ref for generic stamp: TR900 -> ref_num\n",
    "        \n",
    "        # remove punctuation \n",
    "        removeSyms = string.punctuation \n",
    "        # include underscore for above masks \n",
    "        removeSyms = removeSyms.replace(\"_\", \"\")\n",
    "        pattern=r\"[{}]\".format(removeSyms)\n",
    "        # apply the pattern to the string, remove space, lowercase \n",
    "        convo = re.sub(pattern, \" \", convo.strip().lower())\n",
    "        \n",
    "        # finally, tokenize and exclude stopwords \n",
    "        sent=[word for word in convo.split() if word not in stop]\n",
    "        return \" \".join(sent) \n",
    "        \n",
    "    \n",
    "    def vectorise(self):\n",
    "        \"\"\"method runs tfidf vectoriser\"\"\"\n",
    "        text = self.df.body_text.values\n",
    "        X = self.vectoriser.fit_transform(text)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0f022",
   "metadata": {},
   "source": [
    "4. Utterance classification: train and evaluate a supervised utterance classifier that recognizes utterances of these 5 most common utterance types. How well is the classifier working on unseen utterances of known types? Could you use this classifier to realize a utterance does not belong to any known type, yet properly classify utterances of known types? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30308d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_998/639051618.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df['body_text'] = self.df.text.apply(self.create_vsm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fit 2 clusters\n",
      " Fit 3 clusters\n",
      " Fit 4 clusters\n",
      " Fit 5 clusters\n",
      " Fit 6 clusters\n",
      " Fit 7 clusters\n",
      " Fit 8 clusters\n",
      " Fit 9 clusters\n",
      " Fit 10 clusters\n",
      " Fit 11 clusters\n",
      " Fit 12 clusters\n",
      " Fit 13 clusters\n",
      " Fit 14 clusters\n",
      " Fit 15 clusters\n",
      " Fit 16 clusters\n",
      " Fit 17 clusters\n",
      " Fit 18 clusters\n",
      " Fit 19 clusters\n",
      " Fit 20 clusters\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_processor=PreProcessText(df_agent_utterances)\n",
    "\n",
    "def find_optimal_num_clusters(data, max_k):\n",
    "    \"\"\" method takes data and target num_clusters and determines optimal number of clusters\"\"\"\n",
    "    iters=range(2,max_k + 1, 1) # set iteration number \n",
    "    inertia_values=[]\n",
    "    \n",
    "    for k in iters:\n",
    "        inertia_values.append(KMeans(n_clusters=k, init='k-means++', \n",
    "                                random_state=10).fit(data).inertia_)\n",
    "        print(' Fit {} clusters'.format(k))\n",
    "        \n",
    "    (f, ax) = plt.subplots(1,1)\n",
    "    ax.plot(iters, inertia_values, marker=\"o\")\n",
    "    ax.set_xlabel(\"cluster nums\")\n",
    "    ax.set_xticks(iters)\n",
    "    ax.set_xticklabels(iters)\n",
    "    ax.set_ylabel(\"inertia\")\n",
    "    ax.set_title(\"inertia per cluster\")\n",
    "    plt.show()\n",
    "\n",
    "X=text_processor.vectorise()\n",
    "find_optimal_num_clusters(X, 20)\n",
    "# optimal number of clusters == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbac67",
   "metadata": {},
   "source": [
    "running the above cell would suggest that the ideal number of clusters would be 10 \n",
    "Further work could focus on drilling into the differences of the clusters, though the suspicion is that there is not enough input data to generate distinct rich clusters. I.E much of the input text is very similar. \n",
    "Proceeding with the assignment brief it was elected to only focus on 5 sub topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "281a66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'else , trip , anything , need , departing , goodbye , help , thank , '\n",
      "    'destination , welcome',\n",
      " 1: 'depart , minutes , day , arrive , trains , travel , leave , would , like '\n",
      "    ', time',\n",
      " 2: 'fee , anything , payable , money_ref , else , booked , station , gbp , '\n",
      "    'number , reference',\n",
      " 3: 'towninfo , centre , wonderful , traveling , good , thank , nice , welcome '\n",
      "    ', great , day',\n",
      " 4: 'work , like , cambridge , book , would , arrives , leaves , train , '\n",
      "    'ref_num , time_stamp'}\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_998/2900760060.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_processor.df['y'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "import numpy as np\n",
    "def get_cluster_themes(data,clusters,labels,n_terms):\n",
    "    \"\"\" method determines the theme of each cluster\"\"\"\n",
    "    themes_dict={}\n",
    "    df=pd.DataFrame(data.todense()).groupby(clusters).mean() # creates a row for each cluster and a column per term \n",
    "    for (i,r) in df.iterrows():\n",
    "        themes_dict[i] = \" , \".join(labels[t] for t in np.argsort(r)[-n_terms:]) # join the weights table that correspod to the top n terms in the cluser row \n",
    "    return themes_dict\n",
    "\n",
    "n5_clusters=KMeans(n_clusters=5, init=\"k-means++\", random_state=10)\n",
    "y_pred=n5_clusters.fit_predict(X.toarray())\n",
    "text_processor.df['y'] = y_pred\n",
    "themes_dict=get_cluster_themes(X, y_pred, text_processor.vectoriser.get_feature_names(), 10)\n",
    "print(pp.pprint(themes_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfa28b",
   "metadata": {},
   "source": [
    "Having run the above cell one could select 5 labels for the documents as follows:\n",
    "1. saluations-leaving\n",
    "2. train-departure_needs-request\n",
    "3. money-request\n",
    "4. arrival-instructions\n",
    "5. booking-depart-instructions\n",
    "\n",
    "Alternatively one could apply LDA to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0ce9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim import corpora\n",
    "from gensim import models \n",
    "import numpy as np\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "\n",
    "# take the processed doc and return to vector to suit gensim input type\n",
    "tokenised_text = [doc.split() for doc in text_processor.df.body_text.values]\n",
    "\n",
    "# cast to a dictionary \n",
    "dictionary=Dictionary(tokenised_text)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenised_text]\n",
    "#print(len(corpus))\n",
    "\n",
    "# to load the dictionary \n",
    "temp=dictionary[0]\n",
    "\n",
    "id2word=dictionary.id2token\n",
    "model=LdaModel(corpus=corpus,\n",
    "                id2word=id2word,\n",
    "                  alpha=\"auto\",\n",
    "                  eta=\"auto\",\n",
    "              iterations=400, \n",
    "              num_topics=5,\n",
    "              passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3feb61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp  refnum  would  train  like  cambridge  book  leaves  arrives  leaving\n",
      "\n",
      "time  trains  day  like  leave  would  arrive  travel  need  available\n",
      "\n",
      "pounds  moneyref  help  destination  could  departing  minutes  glad  price  departure\n",
      "\n",
      "number  reference  else  anything  moneyref  gbp  station  help  booked  payable\n",
      "\n",
      "day  welcome  thank  great  trip  goodbye  using  cambridge  centre  nice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(model.show_topics())\n",
    "for i, r in iter(model.show_topics()):\n",
    "    print(re.sub(r'[^a-z ]+', '', r))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f426766",
   "metadata": {},
   "source": [
    "LDA topics seem to produce less cohesive topic types, loosely speaking one could argue that themes are \n",
    "1. specific-train-time-request\n",
    "2. general-train-time-request\n",
    "3. payment-request\n",
    "4. end-of-transaction\n",
    "5. saluations-bye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd39d57",
   "metadata": {},
   "source": [
    "5. Utterance classification: train and evaluate a supervised utterance classifier that recognizes utterances of these 5 most common utterance types. How well is the classifier working on unseen utterances of known types? Could you use this classifier to realize a utterance does not belong to any known type, yet properly classify utterances of known types? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b360f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ids  turns                  dialog_intent  \\\n",
      "1   SNG0297.json      1                (Train-Request)   \n",
      "3   SNG0297.json      3  (Train-Inform, Train-Request)   \n",
      "5   SNG0297.json      5                 (Train-Inform)   \n",
      "7   SNG0297.json      7                  (general-bye)   \n",
      "9  SNG01450.json      1                (Train-Request)   \n",
      "\n",
      "                                                text  \\\n",
      "1  I 'll be glad to help . You would like to from...   \n",
      "3  I have seven trains , could you tell me when y...   \n",
      "5                             TR7943 leaves at 11:39   \n",
      "7                                 Have a great day !   \n",
      "9      What time and day are you looking to travel ?   \n",
      "\n",
      "                                           body_text  y  \n",
      "1  glad help would like london liverpool street d...  0  \n",
      "3          seven trains could tell would like arrive  1  \n",
      "5                          ref_num leaves time_stamp  4  \n",
      "7                                          great day  3  \n",
      "9                            time day looking travel  1  \n"
     ]
    }
   ],
   "source": [
    "print(text_processor.df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f22945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saluations-leaving               577\n",
      "booking-depart-instructions      427\n",
      "train-departure_needs-request    325\n",
      "arrival-instructions             228\n",
      "money-request                    214\n",
      "Name: term_intent, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_998/150045704.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_processor.df['term_intent'] = text_processor.df.y.apply(cluster_convert)\n"
     ]
    }
   ],
   "source": [
    "def cluster_convert(row):\n",
    "    ''' method iterates over y (the cluster value assigned the doc) \n",
    "    and converts it to a text label which we manually determined'''\n",
    "    \n",
    "    intents = [\"saluations-leaving\",\"train-departure_needs-request\", \"money-request\", \n",
    "                               \"arrival-instructions\", \"booking-depart-instructions\"]\n",
    "    return intents[row]\n",
    "\n",
    "\n",
    "text_processor.df['term_intent'] = text_processor.df.y.apply(cluster_convert)\n",
    "#print(text_processor.df.head())\n",
    "print(text_processor.df.term_intent.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae09c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ids', 'turns', 'dialog_intent', 'text', 'body_text', 'y',\n",
      "       'term_intent'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create a test/train split in our data\n",
    "print(text_processor.df.columns)\n",
    "from sklearn.model_selection import train_test_split \n",
    "train, test = train_test_split(text_processor.df, test_size=0.2)\n",
    "\n",
    "train_data=train.body_text\n",
    "train_labels=train.term_intent\n",
    "\n",
    "test_data=test.body_text\n",
    "test_labels=test.term_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c8369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 13:51:36.546946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdfe55a0ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-02 13:51:36.546972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use large pretrained sentence embeddings that include phrase usage\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder-large/5'\n",
    "embed = hub.KerasLayer(module_url, trainable=True, name='USE_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1337b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 5.720153093338013\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "# one hot encoding \n",
    "y_train=pd.get_dummies(train_labels)\n",
    "y_test=pd.get_dummies(test_labels)\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model(embed):\n",
    "    model=Sequential([\n",
    "        Input(shape=[], dtype=tf.string), \n",
    "        embed,\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model \n",
    "model = build_model(embed)\n",
    "\n",
    "print(\"running time {}\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430e4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 13:52:58.928448: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 438 in the outer inference context.\n",
      "2021-08-02 13:52:58.928673: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 491 in the outer inference context.\n",
      "2021-08-02 13:52:58.928723: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 475 in the outer inference context.\n",
      "2021-08-02 13:52:58.928868: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 523 in the outer inference context.\n",
      "2021-08-02 13:52:58.928893: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 515 in the outer inference context.\n",
      "2021-08-02 13:52:58.928916: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 507 in the outer inference context.\n",
      "2021-08-02 13:52:58.928928: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 499 in the outer inference context.\n",
      "2021-08-02 13:52:58.928961: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 483 in the outer inference context.\n",
      "2021-08-02 13:52:58.929443: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 529 in the outer inference context.\n",
      "2021-08-02 13:52:58.929631: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 521 in the outer inference context.\n",
      "2021-08-02 13:52:58.929841: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 513 in the outer inference context.\n",
      "2021-08-02 13:52:58.929865: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 505 in the outer inference context.\n",
      "2021-08-02 13:52:58.929886: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 497 in the outer inference context.\n",
      "2021-08-02 13:52:58.929909: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 489 in the outer inference context.\n",
      "2021-08-02 13:52:58.929930: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 481 in the outer inference context.\n",
      "2021-08-02 13:52:58.932394: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 495 in the outer inference context.\n",
      "2021-08-02 13:52:58.932426: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 479 in the outer inference context.\n",
      "2021-08-02 13:52:58.932453: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 533 in the outer inference context.\n",
      "2021-08-02 13:52:58.932466: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 527 in the outer inference context.\n",
      "2021-08-02 13:52:58.932479: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 519 in the outer inference context.\n",
      "2021-08-02 13:52:58.932500: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 511 in the outer inference context.\n",
      "2021-08-02 13:52:58.932512: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 503 in the outer inference context.\n",
      "2021-08-02 13:52:58.932526: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 487 in the outer inference context.\n",
      "2021-08-02 13:52:58.932595: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 493 in the outer inference context.\n",
      "2021-08-02 13:52:58.932644: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 477 in the outer inference context.\n",
      "2021-08-02 13:52:58.932700: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 531 in the outer inference context.\n",
      "2021-08-02 13:52:58.932722: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 525 in the outer inference context.\n",
      "2021-08-02 13:52:58.932759: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 517 in the outer inference context.\n",
      "2021-08-02 13:52:58.932781: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 509 in the outer inference context.\n",
      "2021-08-02 13:52:58.932801: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 501 in the outer inference context.\n",
      "2021-08-02 13:52:58.932827: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 485 in the outer inference context.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 13:53:21.764381: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 527 in the outer inference context.\n",
      "2021-08-02 13:53:21.764442: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 519 in the outer inference context.\n",
      "2021-08-02 13:53:21.764469: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 533 in the outer inference context.\n",
      "2021-08-02 13:53:21.764507: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 511 in the outer inference context.\n",
      "2021-08-02 13:53:21.764537: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 525 in the outer inference context.\n",
      "2021-08-02 13:53:21.764559: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 517 in the outer inference context.\n",
      "2021-08-02 13:53:21.764588: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 503 in the outer inference context.\n",
      "2021-08-02 13:53:21.764610: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 531 in the outer inference context.\n",
      "2021-08-02 13:53:21.764645: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 509 in the outer inference context.\n",
      "2021-08-02 13:53:21.764682: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 523 in the outer inference context.\n",
      "2021-08-02 13:53:21.764703: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 515 in the outer inference context.\n",
      "2021-08-02 13:53:21.764729: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 501 in the outer inference context.\n",
      "2021-08-02 13:53:21.764747: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 495 in the outer inference context.\n",
      "2021-08-02 13:53:21.764809: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 507 in the outer inference context.\n",
      "2021-08-02 13:53:21.764890: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 487 in the outer inference context.\n",
      "2021-08-02 13:53:21.764914: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 479 in the outer inference context.\n",
      "2021-08-02 13:53:21.764935: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 529 in the outer inference context.\n",
      "2021-08-02 13:53:21.764955: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 521 in the outer inference context.\n",
      "2021-08-02 13:53:21.764975: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 513 in the outer inference context.\n",
      "2021-08-02 13:53:21.765003: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 499 in the outer inference context.\n",
      "2021-08-02 13:53:21.765022: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 493 in the outer inference context.\n",
      "2021-08-02 13:53:21.765084: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 505 in the outer inference context.\n",
      "2021-08-02 13:53:21.765124: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 485 in the outer inference context.\n",
      "2021-08-02 13:53:21.765146: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 477 in the outer inference context.\n",
      "2021-08-02 13:53:21.765192: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 497 in the outer inference context.\n",
      "2021-08-02 13:53:21.765230: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 491 in the outer inference context.\n",
      "2021-08-02 13:53:21.765348: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 483 in the outer inference context.\n",
      "2021-08-02 13:53:21.765421: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 489 in the outer inference context.\n",
      "2021-08-02 13:53:21.765453: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 475 in the outer inference context.\n",
      "2021-08-02 13:53:21.765495: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 481 in the outer inference context.\n",
      "2021-08-02 13:53:21.765669: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 438 in the outer inference context.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 1.5621 - accuracy: 0.4594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 13:58:15.897903: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Python/3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Python/3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 592s 16s/step - loss: 1.5621 - accuracy: 0.4594 - val_loss: 1.5286 - val_accuracy: 0.5810\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.6166INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 626s 17s/step - loss: 1.4781 - accuracy: 0.6166 - val_loss: 1.4466 - val_accuracy: 0.6268\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.3885 - accuracy: 0.6776INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 619s 17s/step - loss: 1.3885 - accuracy: 0.6776 - val_loss: 1.3544 - val_accuracy: 0.7148\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.2884 - accuracy: 0.7606INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 425s 12s/step - loss: 1.2884 - accuracy: 0.7606 - val_loss: 1.2495 - val_accuracy: 0.8169\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.1788 - accuracy: 0.8463WARNING:tensorflow:5 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 382s 11s/step - loss: 1.1788 - accuracy: 0.8463 - val_loss: 1.1377 - val_accuracy: 0.8556\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0676 - accuracy: 0.8922WARNING:tensorflow:6 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 488s 14s/step - loss: 1.0676 - accuracy: 0.8922 - val_loss: 1.0290 - val_accuracy: 0.8979\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9647 - accuracy: 0.9170WARNING:tensorflow:7 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 589s 16s/step - loss: 0.9647 - accuracy: 0.9170 - val_loss: 0.9340 - val_accuracy: 0.9261\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.8759 - accuracy: 0.9382WARNING:tensorflow:8 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 527s 15s/step - loss: 0.8759 - accuracy: 0.9382 - val_loss: 0.8577 - val_accuracy: 0.9437\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.8056 - accuracy: 0.9496WARNING:tensorflow:9 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 482s 13s/step - loss: 0.8056 - accuracy: 0.9496 - val_loss: 0.8010 - val_accuracy: 0.9437\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.9594WARNING:tensorflow:10 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 576s 16s/step - loss: 0.7525 - accuracy: 0.9594 - val_loss: 0.7617 - val_accuracy: 0.9401\n",
      "running time 5509.5010759830475\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"tmp/checkpoint\", monitor=\"val_loss\", save_best_only=True)\n",
    "\n",
    "train_logs=model.fit(train_data, y_train, validation_split=0.20, \n",
    "                    epochs = 10, \n",
    "                    callbacks=[checkpoint], batch_size=32)\n",
    "\n",
    "print(\"running time {}\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3070b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               precision    recall  f1-score   support\n",
      "\n",
      "         arrival-instructions       0.90      1.00      0.95        36\n",
      "  booking-depart-instructions       0.97      0.93      0.95        76\n",
      "                money-request       0.94      1.00      0.97        48\n",
      "           saluations-leaving       0.97      0.95      0.96       128\n",
      "train-departure_needs-request       0.92      0.90      0.91        67\n",
      "\n",
      "                     accuracy                           0.95       355\n",
      "                    macro avg       0.94      0.96      0.95       355\n",
      "                 weighted avg       0.95      0.95      0.95       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Preds=[]\n",
    "rawPreds = model.predict(test_data)\n",
    "for j in range(rawPreds.shape[0]):\n",
    "    pos=rawPreds[j].argmax()\n",
    "    Preds.append(y_test.columns[pos])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(Preds, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a792fb",
   "metadata": {},
   "source": [
    "The above shows that the clustering obviously found some connection within the terms that has been vlidated through the supervised approach. Further investigation shows that the agent utterances have also been labelled in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e8d0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Request         320\n",
      "general-bye           252\n",
      "Train-Inform          193\n",
      "Train-OfferBooked     109\n",
      "general-reqmore        51\n",
      "Train-OfferBook        24\n",
      "general-welcome        19\n",
      "general-greet          19\n",
      "Train-Select            5\n",
      "Train-NoOffer           3\n",
      "Restaurant-Request      2\n",
      "Booking-Book            1\n",
      "Taxi-Request            1\n",
      "Booking-Request         1\n",
      "general-thank           1\n",
      "Restaurant-NoOffer      1\n",
      "Restaurant-Inform       1\n",
      "Name: intent, dtype: int64\n",
      "Train-Request         0.319043\n",
      "general-bye           0.251246\n",
      "Train-Inform          0.192423\n",
      "Train-OfferBooked     0.108674\n",
      "general-reqmore       0.050847\n",
      "Train-OfferBook       0.023928\n",
      "general-welcome       0.018943\n",
      "general-greet         0.018943\n",
      "Train-Select          0.004985\n",
      "Train-NoOffer         0.002991\n",
      "Restaurant-Request    0.001994\n",
      "Booking-Book          0.000997\n",
      "Taxi-Request          0.000997\n",
      "Booking-Request       0.000997\n",
      "general-thank         0.000997\n",
      "Restaurant-NoOffer    0.000997\n",
      "Restaurant-Inform     0.000997\n",
      "Name: intent, dtype: float64\n",
      "Train-Request        320\n",
      "general-bye          252\n",
      "Train-Inform         193\n",
      "Train-OfferBooked    109\n",
      "general-reqmore       51\n",
      "Name: intent, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_998/379945193.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_agent_utterances[\"intent_list\"] = df_agent_utterances.dialog_intent.apply(extract_dialog_intent)\n",
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_998/379945193.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_agent_utterances[\"instances\"] = df_agent_utterances.intent_list.apply(count_instances)\n",
      "/var/folders/9t/cmsf896j78b50t605vx52k640000gn/T/ipykernel_998/379945193.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data[\"intent\"] = df_data.intent_list.apply(convert_list_to_str)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_dialog_intent(row):\n",
    "    return list(row)\n",
    "\n",
    "def count_instances(row):\n",
    "    return len(row)\n",
    "\n",
    "def convert_list_to_str(row):\n",
    "    return row[0]\n",
    "\n",
    "df_agent_utterances[\"intent_list\"] = df_agent_utterances.dialog_intent.apply(extract_dialog_intent)\n",
    "df_agent_utterances[\"instances\"] = df_agent_utterances.intent_list.apply(count_instances)\n",
    "df_data=df_agent_utterances[df_agent_utterances.instances == 1 ] # so just one clear intent \n",
    "\n",
    "df_data[\"intent\"] = df_data.intent_list.apply(convert_list_to_str)\n",
    "\n",
    "print(df_data.intent.value_counts())\n",
    "print(df_data.intent.value_counts(normalize=True))\n",
    "# drop all data below 5%\n",
    "value_counts = df_data.intent.value_counts()\n",
    "# identify indexes and use to drop less frequent data\n",
    "to_remove=value_counts[value_counts <= 50].index\n",
    "# retain all other data \n",
    "df = df_data[~df_data.intent.isin(to_remove)]\n",
    "print(df.intent.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d31698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 10)\n",
      "(185, 10)\n"
     ]
    }
   ],
   "source": [
    "# again we split our data in test and train data \n",
    "train, test=train_test_split(df, test_size=0.2)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train_data=train.text \n",
    "train_labels=train.intent\n",
    "test_data=test.text\n",
    "test_labels=test.intent\n",
    "\n",
    "# one hot encoding \n",
    "y_train=pd.get_dummies(train_labels)\n",
    "y_test=pd.get_dummies(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e73383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE_embedding (KerasLayer)   (None, 512)               147354880 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 147,357,445\n",
      "Trainable params: 147,357,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "      Train-Inform  Train-OfferBooked  Train-Request  general-bye  \\\n",
      "1793             1                  0              0            0   \n",
      "351              0                  0              1            0   \n",
      "1873             0                  0              1            0   \n",
      "1347             0                  0              0            1   \n",
      "2661             0                  0              1            0   \n",
      "...            ...                ...            ...          ...   \n",
      "2249             0                  0              0            1   \n",
      "2047             0                  0              0            0   \n",
      "1113             0                  0              0            1   \n",
      "3111             0                  1              0            0   \n",
      "453              1                  0              0            0   \n",
      "\n",
      "      general-reqmore  \n",
      "1793                0  \n",
      "351                 0  \n",
      "1873                0  \n",
      "1347                0  \n",
      "2661                0  \n",
      "...               ...  \n",
      "2249                0  \n",
      "2047                1  \n",
      "1113                0  \n",
      "3111                0  \n",
      "453                 0  \n",
      "\n",
      "[740 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# using the previous model settings \n",
    "print(model.summary())\n",
    "checkpoint2=ModelCheckpoint(\"tmp/checkpoint2\", monitor=\"val_loss\", save_only_best=True)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c5fed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.6853 - accuracy: 0.1740WARNING:tensorflow:11 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 458s 24s/step - loss: 1.6853 - accuracy: 0.1740 - val_loss: 1.5129 - val_accuracy: 0.2905\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.4092 - accuracy: 0.3176WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 593s 31s/step - loss: 1.4092 - accuracy: 0.3176 - val_loss: 1.2879 - val_accuracy: 0.4122\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.2043 - accuracy: 0.6115WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 791s 42s/step - loss: 1.2043 - accuracy: 0.6115 - val_loss: 1.1127 - val_accuracy: 0.7230\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.0455 - accuracy: 0.7889WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1089s 57s/step - loss: 1.0455 - accuracy: 0.7889 - val_loss: 0.9859 - val_accuracy: 0.8378\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.9338 - accuracy: 0.8801WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1177s 62s/step - loss: 0.9338 - accuracy: 0.8801 - val_loss: 0.8896 - val_accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.8553 - accuracy: 0.9139WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 940s 49s/step - loss: 0.8553 - accuracy: 0.9139 - val_loss: 0.8213 - val_accuracy: 0.9392\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.9172WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 989s 52s/step - loss: 0.7991 - accuracy: 0.9172 - val_loss: 0.7739 - val_accuracy: 0.9392\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.9341WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1772s 93s/step - loss: 0.7584 - accuracy: 0.9341 - val_loss: 0.7387 - val_accuracy: 0.9662\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7272 - accuracy: 0.9459WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 628s 33s/step - loss: 0.7272 - accuracy: 0.9459 - val_loss: 0.7125 - val_accuracy: 0.9797\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7021 - accuracy: 0.9645WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x17d16aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/checkpoint2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "19/19 [==============================] - 965s 51s/step - loss: 0.7021 - accuracy: 0.9645 - val_loss: 0.6920 - val_accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "train_data=model.fit(train_data,y_train, validation_split=0.2, \n",
    "                    epochs=10, callbacks=[checkpoint2], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cdd54d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# display the loss curve \n",
    "plt.clf()\n",
    "\n",
    "transaction_dict=train_data.history\n",
    "loss_values=transaction_dict[\"loss\"]\n",
    "val_loss_values=transaction_dict[\"val_loss\"]\n",
    "epochs=range(1,len(transaction_dict[\"loss\"]) + 1)\n",
    "plt.plot(epochs,loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"r\", label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#validation accuracy \n",
    "plt.clf()\n",
    "acc_values=transaction_dict[\"accuracy\"]\n",
    "val_acc_values=transaction_dict[\"val_accuracy\"]\n",
    "epochs=range(1, len(transaction_dict[\"accuracy\"])+1)\n",
    "plt.plot(epochs, acc_values, 'bo', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc_values, \"r\", label=\"Validation Acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59869ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 5)\n",
      "185\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Train-Inform       0.97      0.93      0.95        40\n",
      "Train-OfferBooked       0.88      0.93      0.90        15\n",
      "    Train-Request       0.99      1.00      0.99        66\n",
      "      general-bye       1.00      1.00      1.00        55\n",
      "  general-reqmore       1.00      1.00      1.00         9\n",
      "\n",
      "         accuracy                           0.98       185\n",
      "        macro avg       0.97      0.97      0.97       185\n",
      "     weighted avg       0.98      0.98      0.98       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating mmodel on the hold out data \n",
    "rawPreds = model.predict(test_data)\n",
    "print(rawPreds.shape)\n",
    "\n",
    "Preds=[]\n",
    "for j in range(rawPreds.shape[0]):\n",
    "    pos=rawPreds[j].argmax()\n",
    "    Preds.append(y_test.columns[pos])\n",
    "    \n",
    "print(len(Preds))\n",
    "\n",
    "print(classification_report(Preds, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ba9f4",
   "metadata": {},
   "source": [
    "4. b Could you use this classifier to realize a utterance does not belong to any known type, yet properly classify utterances of known types? How?\n",
    "\n",
    "one can easily test the model by looking at the probability outputs that a  given utterances will belong to a given class. Using a threshold one could establish a confidence level/ a boundary of acceptability. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eba6729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2713492  0.10884184 0.3590473  0.12065468 0.140107  ]]\n"
     ]
    }
   ],
   "source": [
    "test=model.predict([\"can you tell me when the next one is heading to cork is ?\"])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aed70b",
   "metadata": {},
   "source": [
    "5. Next steps: if you had more time to further develop this proof of concept, \n",
    "    what would you propose to do in a next iteration in order to accelerate and \n",
    "    improve the analysis of agent utterances?\n",
    "\n",
    " The model seems to be classifying with  high degree of accuracy. With a 98% degree accuracy rate, it would make sense to review the data and ensure that what we are being accurate in our predictions from the analysis up to this point. I would recommend drilling into what distinguishes the various classes. Put another way, what attributes have the highest entropy in affecting the classification ?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f8c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
